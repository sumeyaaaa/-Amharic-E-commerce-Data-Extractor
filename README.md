# -Amharic-E-commerce-Data-Extractor
Amharic E-Commerce Entity Extraction is a machine learning pipeline that scrapes Amharic Telegram e-commerce posts and fine-tunes a multilingual transformer model to extract key business entities like Product, Price, and Location,  helping EthioMart become the central hub for Telegram-based digital commerce in Ethiopia.

This project is part of a data annotation and modeling pipeline for Amharic Telegram e-commerce channels. It includes data scraping, preprocessing, manual annotation in CoNLL format, and visualizations.
--

## ğŸ“ Directory Structure of AMHARIC-E-COMMERCE-DATA-EXTRACTOR

```
â”œâ”€â”€ .github/                             # GitHub actions and workflows
â”œâ”€â”€ .venv/                               # Python virtual environment
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â”œâ”€â”€ conull.csv                   # Final labeled data in CoNLL table format
â”‚   â”‚   â”œâ”€â”€ telegram_scraped_data_cleaned.csv  # Cleaned Telegram messages
â”‚   â”‚   â””â”€â”€ top_30_messages_per_channel.csv    # Top 30 messages per channel for annotation
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ images/                      # Downloaded product images
â”‚   â”‚   â””â”€â”€ telegram_scraped_data.csv   # Raw scraped Telegram messages
â”‚
â”œâ”€â”€ models/                              # Folder for storing fine-tuned NER models
â”‚
â”œâ”€â”€ notebook/
â”‚   â”œâ”€â”€ task-1/
â”‚   â”‚   â”œâ”€â”€ normalization_and_tokenization.ipynb # Preprocessing pipeline
â”‚   â”‚   â”œâ”€â”€ scrapper_session.session              # Telethon session file
â”‚   â”‚   â””â”€â”€ scrapping.ipynb                       # Telegram scraping script
â”‚   â”œâ”€â”€ task-2/
â”‚   â”‚   â”œâ”€â”€ coNull.ipynb                          # CoNLL labeling and analysis
â”‚   â”‚   â””â”€â”€ conll_ready_tokenized.txt            # Tokenized text for manual labeling
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py                    # Channel list, phone, and output paths
â”‚   â”œâ”€â”€ pre_processing.py            # Amharic text cleaning and normalization
â”‚   â”œâ”€â”€ scrapper.py                  # Telegram scraping with Telethon
â”‚   â”œâ”€â”€ coNLL.py                     # Exporting CoNLL formatted files and label analysis
â”‚   â””â”€â”€ visualization.py            # Word counts, channel stats, font-safe Amharic plots
â”‚
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ .gitignore                       # Files to ignore by Git
â””â”€â”€ README.md                        # This file
```

---

## ğŸ”¨ Setup & Installation

```bash
# Clone the repo
$ git clone https://github.com/sumeyaaaa/-Amharic-E-commerce-Data-Extractor.git
$ cd -Amharic-E-commerce-Data-Extractor

# Create virtual environment
$ python -m venv .venv
$ .venv\Scripts\activate      # On Windows

# Install dependencies
$ pip install -r requirements.txt
```

---

## ğŸ“Œ Key Tasks

### âœ… Task 1: Scraping & Preprocessing
- Scrape Amharic e-commerce content using **Telethon**.
- Normalize and clean the Amharic text.
- Select top 30 messages per channel.

### âœ… Task 2: CoNLL Annotation Prep
- Export cleaned tokens in a `.txt` file ready for manual labeling.
- Load manually labeled CoNLL table and compute label coverage.

### ğŸ“Š Visualizations
- Top N most common words
- Bar chart of message counts per channel
- Custom font support for Amharic text using `Abyssinica SIL`

---
###  Task 3: Fine-Tune NER Model
Use pretrained models:

xlm-roberta-base

bert-tiny-amharic

afroxlmr

Tokenize and align labels

Train using Hugging Faceâ€™s Trainer API

###  Task 4: Model Comparison
Evaluate multiple models (XLM-R, DistilBERT, mBERT)

Compare F1-score, training speed, token alignment issues

Select the best for production

###  Task 5: Interpretability with SHAP & LIME
Use SHAP to analyze token-level contributions

Use LIME for local explanations on misclassified entities

Identify weaknesses in model handling ambiguous or nested entities

###  Task 6: FinTech Vendor Scorecard
Compute per-vendor metrics:

ğŸ•’ Posts per week (activity)

ğŸ‘ï¸ Average views per post (engagement)

ğŸ’° Average product price (business profile)

###  Combine into a custom Lending Score

python
Copy
Edit
lending_score = (avg_views * 0.5) + (posts_per_week * 0.5)
Present results in a comparative table

###  Learning Outcomes
By completing this project, you will:

Build a full-stack NLP pipeline from raw data collection to model interpretation

Adapt LLMs (like XLM-R) to low-resource languages (Amharic)

Use SHAP and LIME for trustworthy model deployment

Design analytics tools for FinTech and e-commerce decision-making

###  Dependencies
bash
Copy
Edit
transformers
datasets
pandas
numpy
telethon
scikit-learn
shap
lime
matplotlib
Install them via:

bash
Copy
Edit
pip install -r requirements.txt
ğŸ“ References
Getting Started with Hugging Face NER

SHAP Documentation

LIME GitHub Repo

Amharic NER Dataset

###  Final Deliverables
âœ… GitHub repo with all scripts and models

âœ… PDF Report:

###  Methodology

Model results

Vendor scorecard

Interpretation summary



---

## ğŸ“Œ Labels Used for Annotation

- `O` â€” Outside any entity
- `B-PRODUCT`, `I-PRODUCT`
- `B-AUDIENCE`
- `B-BRAND`, `I-BRAND`
- `B-COMPONENT`, `I-COMPONENT`
- `B-TASK`, `I-TASK`
- `B-CONTACT_INFO`
- `B-PRICE`, `I-PRICE`
- `B-LOC`, `I-LOC`
- `B-DATE`, `I-DATE`
- `B-FEATURE`, `I-FEATURE`
- `B-ATTRIBUTE`, `I-ATTRIBUTE`

---

## ğŸ“Š Labeling Stats
After cleaning:
- **Total tokens** = _N_
- **Labeled tokens (not 'O')** = _M_
- **Coverage** = _(M / N) * 100%_

(To be updated after each labeling batch)

---

## ğŸš€ Future Plans
- Complete model training and evaluation.
- Integrate prediction pipeline into EthioMartâ€™s backend.
- Build a scoring engine to rank vendors based on posting frequency, product diversity, and customer engagement.

---


## ğŸ“¦ Module Overview

### `src/config.py`
Configuration: phone number, channel usernames, and file paths.

### `src/pre_processing.py`
- Clean Amharic text (remove punctuations, links, emojis).
- Normalize characters for consistent tokenization.

### `src/scrapper.py`
- Login and fetch messages using Telethon.
- Save raw messages with metadata.

### `src/coNLL.py`
- Tokenizes messages and exports token-per-line `.txt`.
- Loads labeled data and analyzes how many tokens are labeled.

### `src/visualization.py`
- `plot_channel_distribution()` for message counts.
- `plot_top_words()` to show frequent words in Amharic (with font).

---

## ğŸ“Š Amharic Font Setup for Visualization
To render Amharic glyphs in plots:
1. Download [Abyssinica SIL](https://software.sil.org/abyssinica/download/)
2. Place `AbyssinicaSIL-Regular.ttf` in a `fonts/` directory
3. Use the font in visualization:

```python
plot_top_words(
  df,
  text_column="text",
  top_n=20,
  title="áŠ¨áá‰°áŠ› á‹¨á‰°á‹°áŒˆáˆ˜ á‰ƒáˆ‹á‰µ",
  font_path="fonts/AbyssinicaSIL-Regular.ttf"
)
```

---

## ğŸ§  Future Improvements
- Train a Named Entity Recognition (NER) model on labeled CoNLL data
- Expand to multi-platform Amharic datasets
- Improve normalization for OCR text

---

## ğŸ“© Contact
Developed by [@sumeyaaaa](https://github.com/sumeyaaaa)

---

**Note**: This project is part of a 10 Academy Week 4 challenge.

## ğŸ§ª Setup Instructions

### Requirements
- Python 3.8+
- pandas, regex, telethon
- Jupyter Notebook

### Run scraping:
```bash
jupyter notebook notebook/task-1/scrapping.ipynb
